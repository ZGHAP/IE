{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select * from AINDEXMEMBERS\n",
    "#where S_INFO_WINDCODE = '000300.SH' and YEAR(OPDATE)='2016' and MONTH(OPDATE)='12' and DAY(OPDATE)='09'\n",
    "\n",
    "#注意FIND_IN_SET中的字符串中，代码间不能有空格，否则只有第一个代码有效\n",
    "#另外尽量不要用OPDATE作为时间控制字段\n",
    "#select * from ASHAREINTENSITYTREND\n",
    "#where YEAR(OPDATE)='2016' and MONTH(OPDATE)='12' and DAY(OPDATE)='09'\n",
    "#and FIND_IN_SET(S_INFO_WINDCODE,'603099.SH,002302.SZ')\n",
    "\n",
    "#select * from ASHARECALENDAR where FIND_IN_SET(S_INFO_EXCHMARKET,'SZSE,SSE') and TRADE_DAYS BETWEEN 20110407 \n",
    "#and 20110430 ORDER BY TRADE_DAYS desc limit 2\n",
    "#select * from ASHARECALENDAR where FIND_IN_SET(S_INFO_EXCHMARKET,'SZSE,SSE') and TRADE_DAYS LIKE '202005%' ORDER BY TRADE_DAYS desc limit 2\n",
    "#select TRADE_DAYS from ASHARECALENDAR where FIND_IN_SET(S_INFO_EXCHMARKET,'SSE') and TRADE_DAYS LIKE '202005%' ORDER BY TRADE_DAYS desc limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/AI2/IE/factor_preprocess/factors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rqdatac as rq\n",
    "import calendar\n",
    "import pymysql\n",
    "import os\n",
    "import re\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from rqdatac import *\n",
    "from datetime import datetime, timedelta, date\n",
    "from collections import OrderedDict\n",
    "from params import connect_info\n",
    "\n",
    "work_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "file_path = os.path.join(work_dir, 'factor_preprocess', 'factors')\n",
    "save_path = os.path.join(work_dir, 'factor_preprocess', 'factors_done')\n",
    "print(file_path)\n",
    "\n",
    "engine = create_engine(connect_info)\n",
    "\n",
    "global file_path, save_path, industry_benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2019-1-1\", date.today().strftime('%Y-%m-%d')]\n",
    "start, end = [datetime.strptime(_, \"%Y-%m-%d\") for _ in dates]\n",
    "dates_dict = OrderedDict(((start + timedelta(_)).strftime(r\"%Y-%m\"), None) for _ in range((end - start).days)).keys()\n",
    "dates_series = [_ for _ in dates_dict]\n",
    "#dates_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222222\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a355602ed00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdate_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdate_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%%'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlast_day_sql_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0mselect\u001b[0m \u001b[0mTRADE_DAYS\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mASHARECALENDAR\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mFIND_IN_SET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_INFO_EXCHMARKET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SSE'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mTRADE_DAYS\u001b[0m \u001b[0mLIKE\u001b[0m \u001b[0;34m'{date_range}'\u001b[0m \u001b[0mORDER\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mTRADE_DAYS\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for fpath in os.listdir(file_path)[:]:\n",
    "    print(fpath)\n",
    "    all_data = pd.DataFrame()\n",
    "    date_range = fpath.split('.')[0].split('-')\n",
    "    date_range = date_range[0] + date_range[1] + '%%'\n",
    "    last_day_sql_cmd = f\"select TRADE_DAYS from ASHARECALENDAR where FIND_IN_SET(S_INFO_EXCHMARKET,'SSE') and \\\n",
    "                        TRADE_DAYS LIKE '{date_range}' ORDER BY TRADE_DAYS desc limit 1\"\n",
    "    trade_day = pd.read_sql(sql= last_day_sql_cmd, con = engine).TRADE_DAYS.tolist()[0]\n",
    "    #print(trade_day[:4],trade_day[4:6],trade_day[6:8])\n",
    "\n",
    "    origin_df = pd.read_csv(os.path.join(file_path, fpath), engine='c',encoding='gbk', index_col=[0])\n",
    "    #print(origin_df.iloc[:,:8])\n",
    "    sec_code = str(origin_df.code.tolist()[:])\n",
    "    origin_df = origin_df.iloc[:,:7].set_index(origin_df.code)\n",
    "                    \n",
    "    sec_code = re.sub('[\\ \\[\\]\\']', '', sec_code)\n",
    "    sec_code = f\"'{sec_code}'\"\n",
    "    sec_code_series = f'FIND_IN_SET(S_INFO_WINDCODE,{sec_code})'\n",
    "    print(f'dealing with {fpath}')\n",
    "    \n",
    "    # round 1\n",
    "    # 统计因子\n",
    "    Indicator_Name = 'S_INFO_WINDCODE PCT_CHANGE_M ALPHA_DAY_1Y TURNOVER_M STD_DEVIATION_24M ' + \\\n",
    "                    'TURNOVER_D_FLOAT TURNOVER_W_FLOAT TURNOVER_M_FLOAT'\n",
    "    Indicator_Name = Indicator_Name.replace(' ', ',')\n",
    "    #Indicator_Name = '*'\n",
    "    Table_Name = 'ASHAREYIELD'\n",
    "    condiction = f\" WHERE YEAR(TRADE_DT)={trade_day[0:4]} AND \\\n",
    "                    MONTH(TRADE_DT)={trade_day[4:6]} AND \\\n",
    "                    DAY(TRADE_DT)={trade_day[6:8]} AND \\\n",
    "                    {sec_code_series}\" \n",
    "    sql_cmd = f'select {Indicator_Name} from {Table_Name} {condiction}'\n",
    "    #print(sql_cmd)\n",
    "    \n",
    "    print(Table_Name)\n",
    "    sql_df = pd.read_sql(sql= sql_cmd, con = engine)\n",
    "    sql_df = sql_df.set_index(sql_df.S_INFO_WINDCODE)\n",
    "    sql_df.rename(columns={'PCT_CHANGE_M': 'PCT_CHG_NM'}, inplace=True)\n",
    "    sql_df.rename(columns={'TURNOVER_D_FLOAT': 'STOA_Barra'}, inplace=True)\n",
    "    sql_df.rename(columns={'TURNOVER_W_FLOAT': 'STOW_Barra'}, inplace=True)\n",
    "    sql_df.rename(columns={'TURNOVER_M_FLOAT': 'STOM_Barra'}, inplace=True)\n",
    "    #print(origin_df.shape,sql_df.shape)\n",
    "    all_data = pd.concat([origin_df, sql_df], axis = 1)\n",
    "    \n",
    "    # round 2\n",
    "    # 技术因子\n",
    "    Indicator_Name = 'S_INFO_WINDCODE MA_20D MACD_DIFF MACD_DEA MACD_MACD'\n",
    "    Indicator_Name = Indicator_Name.replace(' ', ',')\n",
    "    #Indicator_Name = '*'\n",
    "    Table_Name = 'ASHAREINTENSITYTREND'\n",
    "    condiction = f\" WHERE YEAR(TRADE_DT)={trade_day[0:4]} AND \\\n",
    "                    MONTH(TRADE_DT)={trade_day[4:6]} AND \\\n",
    "                    DAY(TRADE_DT)={trade_day[6:8]} AND \\\n",
    "                    {sec_code_series}\" \n",
    "    sql_cmd = f'select {Indicator_Name} from {Table_Name} {condiction}'\n",
    "    #print(sql_cmd)\n",
    "            \n",
    "    print(Table_Name)\n",
    "    sql_df = pd.read_sql(sql= sql_cmd, con = engine)\n",
    "    sql_df = sql_df.set_index(sql_df.S_INFO_WINDCODE)\n",
    "    #print(origin_df.shape,sql_df.shape)\n",
    "    all_data = pd.concat([all_data, sql_df], axis = 1)\n",
    "    \n",
    "    # round 3\n",
    "    # 市值相关\n",
    "    Indicator_Name = 'S_INFO_WINDCODE S_VAL_MV S_VAL_PE S_VAL_PE_TTM S_DQ_MV S_VAL_PCF_NCFTTM '+ \\\n",
    "                    'NET_CASH_FLOWS_OPER_ACT_TTM NET_INCR_CASH_CASH_EQU_TTM S_VAL_PB_NEW NET_PROFIT_PARENT_COMP_TTM'\n",
    "    Indicator_Name = Indicator_Name.replace(' ', ',')\n",
    "    Table_Name = 'ASHAREEODDERIVATIVEINDICATOR'\n",
    "    condiction = f\" WHERE YEAR(TRADE_DT)={trade_day[0:4]} AND \\\n",
    "                    MONTH(TRADE_DT)={trade_day[4:6]} AND \\\n",
    "                    DAY(TRADE_DT)={trade_day[6:8]} AND \\\n",
    "                    {sec_code_series}\" \n",
    "    sql_cmd = f'select {Indicator_Name} from {Table_Name} {condiction}'\n",
    "    #print(sql_cmd)\n",
    "            \n",
    "    print(Table_Name)\n",
    "    sql_df = pd.read_sql(sql= sql_cmd, con = engine)\n",
    "    sql_df = sql_df.set_index(sql_df.S_INFO_WINDCODE)\n",
    "    sql_df['LNCAP_barra'] = np.log(sql_df.S_DQ_MV)\n",
    "    sql_df['BP'] = (1 / sql_df.S_DQ_MV)\n",
    "    sql_df['BTOP_Barra'] = (1 / sql_df.S_DQ_MV)\n",
    "    sql_df['CETOP_Barra'] = (1 / sql_df.S_VAL_PCF_NCFTTM)\n",
    "    sql_df['ETOP_Barra'] = (1 / sql_df.S_VAL_PE)\n",
    "    sql_df['EP'] = (1 / sql_df.S_VAL_PE_TTM)\n",
    "    sql_df['GPE'] = (sql_df.NET_PROFIT_PARENT_COMP_TTM / sql_df.S_VAL_PE_TTM)\n",
    "    sql_df['OCFP'] = (1 / sql_df.NET_CASH_FLOWS_OPER_ACT_TTM)\n",
    "    sql_df['NCFP'] = (1 / sql_df.NET_INCR_CASH_CASH_EQU_TTM)\n",
    "    sql_df.rename(columns={'S_DQ_MV': 'MKT_CAP_FLOAT'}, inplace=True)\n",
    "    #print(origin_df.shape,sql_df.shape)\n",
    "    all_data = pd.concat([all_data, sql_df], axis = 1)\n",
    "    \n",
    "    # round 4\n",
    "    # 交易状态\n",
    "    Indicator_Name = 'S_INFO_WINDCODE S_DQ_TRADESTATUS'\n",
    "    Indicator_Name = Indicator_Name.replace(' ', ',')\n",
    "    Table_Name = 'ASHAREEODPRICES'\n",
    "    condiction = f\" WHERE YEAR(TRADE_DT)={trade_day[0:4]} AND \\\n",
    "                    MONTH(TRADE_DT)={trade_day[4:6]} AND \\\n",
    "                    DAY(TRADE_DT)={trade_day[6:8]} AND \\\n",
    "                    {sec_code_series}\" \n",
    "    sql_cmd = f'select {Indicator_Name} from {Table_Name} {condiction}'\n",
    "    #print(sql_cmd)\n",
    "            \n",
    "    print(Table_Name)\n",
    "    sql_df = pd.read_sql(sql= sql_cmd, con = engine)\n",
    "    sql_df = sql_df.set_index(sql_df.S_INFO_WINDCODE)\n",
    "    #print(origin_df.shape,sql_df.shape)\n",
    "    all_data = pd.concat([all_data, sql_df], axis = 1)\n",
    "    \n",
    "    # round 5\n",
    "    # 技术相关 反转\n",
    "    Indicator_Name = 'S_INFO_WINDCODE BIAS'\n",
    "    Indicator_Name = Indicator_Name.replace(' ', ',')\n",
    "    Table_Name = 'ASHARESWINGREVERSETREND'\n",
    "    condiction = f\" WHERE YEAR(TRADE_DT)={trade_day[0:4]} AND \\\n",
    "                    MONTH(TRADE_DT)={trade_day[4:6]} AND \\\n",
    "                    DAY(TRADE_DT)={trade_day[6:8]} AND \\\n",
    "                    {sec_code_series}\" \n",
    "    sql_cmd = f'select {Indicator_Name} from {Table_Name} {condiction}'\n",
    "    #print(sql_cmd)\n",
    "            \n",
    "    print(Table_Name)\n",
    "    sql_df = pd.read_sql(sql= sql_cmd, con = engine)\n",
    "    sql_df = sql_df.set_index(sql_df.S_INFO_WINDCODE)\n",
    "    #print(origin_df.shape,sql_df.shape)\n",
    "    all_data = pd.concat([all_data, sql_df], axis = 1)\n",
    "    \n",
    "    # round 6\n",
    "    # 财务因子\n",
    "    \n",
    "    \n",
    "    all_data = all_data.reset_index(drop = True)\n",
    "    all_data['is_open1'] = all_data.S_DQ_TRADESTATUS.apply(lambda x:'TRUE' if x == '交易' else 'FALSE')\n",
    "    all_data = all_data.dropna(subset=['S_DQ_TRADESTATUS'])\n",
    "    del all_data['S_INFO_WINDCODE']\n",
    "    del all_data['S_DQ_TRADESTATUS']\n",
    "    \n",
    "    all_data = all_data.dropna()\n",
    "    all_data['No'] = all_data.index\n",
    "    all_data = all_data.set_index(all_data.No, drop = True)\n",
    "    \n",
    "    all_data.to_csv(save_path, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
